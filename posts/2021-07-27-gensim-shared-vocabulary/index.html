<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Luca Papariello">
<meta name="dcterms.date" content="2021-07-27">
<meta name="description" content="A brief illustration of how to share a common vocabulary among different Gensim models.">

<title>Luca’s Blog - Gensim: share vocabulary across models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Luca’s Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/LucaPapariello"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/LPapariello"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Gensim: share vocabulary across models</h1>
                  <div>
        <div class="description">
          A brief illustration of how to share a common vocabulary among different Gensim models.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">nlp</div>
                <div class="quarto-category">gensim</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Luca Papariello </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 27, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#lsi-and-word2vec-the-standard-way" id="toc-lsi-and-word2vec-the-standard-way" class="nav-link" data-scroll-target="#lsi-and-word2vec-the-standard-way">LSI and word2vec the “standard” way</a>
  <ul class="collapse">
  <li><a href="#lsi-model" id="toc-lsi-model" class="nav-link" data-scroll-target="#lsi-model">LSI model</a></li>
  <li><a href="#word2vec-model" id="toc-word2vec-model" class="nav-link" data-scroll-target="#word2vec-model">word2vec model</a></li>
  </ul></li>
  <li><a href="#lsi-and-word2vec-the-fast-way" id="toc-lsi-and-word2vec-the-fast-way" class="nav-link" data-scroll-target="#lsi-and-word2vec-the-fast-way">LSI and word2vec the fast way</a></li>
  <li><a href="#data-streaming-optional" id="toc-data-streaming-optional" class="nav-link" data-scroll-target="#data-streaming-optional">Data streaming [optional]</a>
  <ul class="collapse">
  <li><a href="#lsi-model-1" id="toc-lsi-model-1" class="nav-link" data-scroll-target="#lsi-model-1">LSI model</a></li>
  <li><a href="#word2vec-model-1" id="toc-word2vec-model-1" class="nav-link" data-scroll-target="#word2vec-model-1">word2vec model</a></li>
  </ul></li>
  <li><a href="#acknowledgements-and-references" id="toc-acknowledgements-and-references" class="nav-link" data-scroll-target="#acknowledgements-and-references">Acknowledgements and references</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="quarto-figure quarto-figure-right">
<figure class="figure">
<p><a href="https://www.kaggle.com/code/lucapapariello/gensim-share-vocabulary-across-models"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" class="img-fluid figure-img"></a></p>
</figure>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Deep learning models based on the transformer architecture have taken the NLP world by storm in the last few years, achieving state-of-the-art results in several areas. An obvious example of this success is provided by the tremendous growth of the <a href="https://huggingface.co/">Hugging Face</a> ecosystem, which provides access to a plethora of pre-trained models in a very user-friendly way.</p>
<p>However, we believe that models based on (static) word embeddings still have their place in the “transformer era”. Some reasons why this might be the case are the following:</p>
<ul>
<li>Transformer-based models are usually much bigger (i.e.&nbsp;more parameters) than “standard” models.</li>
<li>Transformer models are not renowned for their (inference) speed—this is related to the previous point.</li>
<li>Models based on word embeddings still provide a solid baseline.</li>
</ul>
<p><a href="https://radimrehurek.com/gensim/">Gensim</a> is a great library when it comes to word embeddings, and some other NLP tasks, especially if you want to train them on your own. There might be cases where you would like to train two NLP models and have them “speak the same language”, i.e.&nbsp;share the <em>same</em> vocabulary. For the sake of concreteness, let’s say these two models are <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing">LSI</a> and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a>. The “standard” way of doing this, however, requires the preparation of <em>two</em> vocabularies, one for each model. In this post, we’ll show how to avoid this by transferring the vocabuly of the LSI model to the word2vec model.</p>
</section>
<section id="lsi-and-word2vec-the-standard-way" class="level1">
<h1>LSI and word2vec the “standard” way</h1>
<p>We will now build these two models following the “standard” procedure as can be found in the respective Gensim documentation. In what follows, we will work with the <a href="http://qwone.com/~jason/20Newsgroups/">20 Newsgroups dataset</a>, which is a collection of ca. 20,000 newsgroup documents grouped into 20 classes. Details are not very important in relation to our discussion. This dataset can easily be downloaded using the <code>sklearn.datasets.fetch_20newsgroups</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html">function</a> of the scikit-learn libray, which will download and cache the dataset.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>data, _ <span class="op">=</span> fetch_20newsgroups(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">123</span>, remove<span class="op">=</span>(<span class="st">'headers'</span>, <span class="st">'footers'</span>, <span class="st">'quotes'</span>), return_X_y<span class="op">=</span><span class="va">True</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="lsi-model" class="level2">
<h2 class="anchored" data-anchor-id="lsi-model">LSI model</h2>
<p>The first step in <a href="https://radimrehurek.com/gensim/models/lsimodel.html">building an LSI model</a> is to create a dictionary, which maps words to integer ids. This is easily achieved through the <code>Dictionary</code> class, to which we have to pass tokenised documents:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>tokenized_data <span class="op">=</span> [tokenizer(doc) <span class="cf">for</span> doc <span class="kw">in</span> data]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>dct <span class="op">=</span> Dictionary(tokenized_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With the help of the dictionary we can then build our corpus using the <code>.doc2bow()</code> method. This returns documents in a bag-of-words (BoW) representation. We could proceed with it, but a <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> representation is preferable, for which we can use the <code>TfidfModel</code> class.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dct.doc2bow(line) <span class="cf">for</span> line <span class="kw">in</span> tokenized_data]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>tfidf_model <span class="op">=</span> TfidfModel(corpus, id2word<span class="op">=</span>dct)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>tfidf_matrix <span class="op">=</span> tfidf_model[corpus]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We have everything we need to build our LSI model, which is conveniently done by the <code>LsiModel</code> class. Without further motivating this arbitrary choice, we set the number of latent dimensions to 200.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>dim_lsi <span class="op">=</span> <span class="dv">200</span>  <span class="co"># Topic number (latent dimension)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>lsi_model <span class="op">=</span> LsiModel(corpus<span class="op">=</span>tfidf_matrix, id2word<span class="op">=</span>dct, num_topics<span class="op">=</span>dim_lsi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 12.6 s, sys: 625 ms, total: 13.2 s
Wall time: 10.5 s</code></pre>
</div>
</div>
<p>We now have an LSI model ready to be used! Let’s move on to word2vec.</p>
</section>
<section id="word2vec-model" class="level2">
<h2 class="anchored" data-anchor-id="word2vec-model">word2vec model</h2>
<p>The quickest way to train a <a href="https://radimrehurek.com/gensim/models/word2vec.html">word2vec model</a> is through the <code>Word2Vec</code> class.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dim_w2v <span class="op">=</span> dim_lsi  <span class="co"># Diminsionality of word vectors</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.025</span>  <span class="co"># Initial learning rate</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>alpha_min <span class="op">=</span> <span class="fl">0.0001</span>  <span class="co"># Drop learning rate to this value</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>wnd <span class="op">=</span> <span class="dv">5</span>        <span class="co"># Window size (max. distance to predicted word)</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>mincount <span class="op">=</span> <span class="dv">2</span>   <span class="co"># Word frequency lower bound</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> <span class="fl">1e-5</span>  <span class="co"># Threshold for downsampling</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>sg <span class="op">=</span> <span class="dv">1</span>         <span class="co"># Index 1 =&gt; Skip-Gram algo.</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>ngt <span class="op">=</span> <span class="dv">10</span>       <span class="co"># No. noisy words for negative sampling</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span>     <span class="co"># No. epochs for training</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>cpus <span class="op">=</span> multiprocessing.cpu_count()  <span class="co"># Tot. no. of CPUs</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>threads <span class="op">=</span> cpus <span class="op">-</span><span class="dv">1</span>  <span class="co"># Use this number of threads for training</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>w2v_model <span class="op">=</span> Word2Vec(</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    sentences<span class="op">=</span>tokenized_data, vector_size<span class="op">=</span>dim_w2v, alpha<span class="op">=</span>alpha, min_alpha<span class="op">=</span>alpha_min, window<span class="op">=</span>wnd, </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    min_count<span class="op">=</span>mincount, sample<span class="op">=</span>sample, sg<span class="op">=</span>sg, negative<span class="op">=</span>ngt, epochs<span class="op">=</span>epochs, workers<span class="op">=</span>threads</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1min 31s, sys: 1.19 s, total: 1min 32s
Wall time: 53.7 s</code></pre>
</div>
</div>
<p>Let’s double-check the number of words present in each of our two models:</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Size of LSI vocab.:'</span>, <span class="bu">len</span>(dct.keys()))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Size of w2v vocab.:'</span>, <span class="bu">len</span>(w2v_model.wv.key_to_index.keys()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Size of LSI vocab.: 42439
Size of w2v vocab.: 42439</code></pre>
</div>
</div>
<p>We’ve hence managed to build an LSI and a word2vec model whose vocabularies contain the exact same words—great! However, this came at an unnecessarily high price and we’ll shortly see why. What happens behind the scenes when we create a new instance of the <code>Word2Vec</code> class is the following. First a quick sanity check of the corpus is performed, then the vocabulary is built using the <code>.build_vocab()</code> method, and lastly the method <code>.train()</code> is executed, which trains the model. In the second step, a new dictionary is built from scratch, despite having already done so for the LSI model. When working with small datasets this procedure might be acceptable, but when the corpus is very large optimising this step can save a lot of time!</p>
</section>
</section>
<section id="lsi-and-word2vec-the-fast-way" class="level1">
<h1>LSI and word2vec the fast way</h1>
<p>We will now see how we can build these models avoiding the above issue. To do that, we must split the creation of the model into three steps. We start by instantiating the model, but without passing it a corpus, i.e.&nbsp;leaving it uninitialised.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>w2v_model <span class="op">=</span> Word2Vec(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span>dim_w2v, alpha<span class="op">=</span>alpha, min_alpha<span class="op">=</span>alpha_min, window<span class="op">=</span>wnd, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    min_count<span class="op">=</span>mincount, sample<span class="op">=</span>sample, sg<span class="op">=</span>sg, negative<span class="op">=</span>ngt, workers<span class="op">=</span>threads</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Thankfully, for the second step, Gensim offers an easy workaround: one can build a vocabulary from a dictionary of <em>word frequencies</em>, instead of from a sequence of sentences as done by default by <code>.build_vocab()</code>. This can be done with the method <code>.build_vocab_from_freq()</code>, which requires a frequency mapping. The latter can be obtained from the LSI dictionary, specifically from the <code>dct.cfs</code> attribute, which contains index to frequency mappings.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: borrow LSI vocab.</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>word_freq <span class="op">=</span> {dct[k]: v <span class="cf">for</span> k,v <span class="kw">in</span> dct.cfs.items()}</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>w2v_model.build_vocab_from_freq(word_freq)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: train model</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>num_samples <span class="op">=</span> dct.num_docs</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>w2v_model.train(tokenized_data, total_examples<span class="op">=</span>num_samples, epochs<span class="op">=</span>epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1min 29s, sys: 812 ms, total: 1min 30s
Wall time: 37.1 s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(2609400, 6277620)</code></pre>
</div>
</div>
<p>We have been successful in creating the word2vec model by borrowing the LSI vocabulary. This allowed us to avoid an unnecessary step and hence to waste resources.</p>
<p>Note that in this case the speed-up is barely observable, which is due to the very small size of the dataset (about 15 MB). However, this becomes considerable when working with huge datasets. The dataset on which I base these conclusions exceeds 50 GB and this second approach saved me <em>several hours</em>!</p>
</section>
<section id="data-streaming-optional" class="level1">
<h1>Data streaming [optional]</h1>
<p>This is a bonus section for those who have endured until this point. The motivation behind this post was to avoid unnecessary calculations, which makes particular sense when dealing with very large datasets. Very large datasets will most likely <em>not</em> fit in the memory, but in the above code we have loaded everything into RAM—ouch!</p>
<p>Gensim models are smart enough to accept <em>iterables</em> that stream the input data directly from disk. In this way, our corpus can be arbitrarily large (limited only by the size of our hard drive). We repeat here the steps of the above sections, but restructuring our code to take advantage of <em>data streaming</em>. We assume the corpus to be stored in a unique text file (<code>20news.txt</code>), which we get by writing the <code>data</code> list to file.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Loading a corpus into memory and then dumping it into a file obviously doesn’t make much sense; we’re doing this only to work with the same data as before. You will not need this step as you will be starting directly from some data stored in a (potentially very large) file.</p>
</div>
</div>
<section id="lsi-model-1" class="level2">
<h2 class="anchored" data-anchor-id="lsi-model-1">LSI model</h2>
<p>As we’ve seen before, the first step is to create a dictionary. Before we passed a list to <code>Dictionary</code>, now we pass it a <em>generator</em>:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>curpus_path <span class="op">=</span> Path(<span class="st">'20news.txt'</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>dct <span class="op">=</span> Dictionary((tokenizer(line) <span class="cf">for</span> line <span class="kw">in</span> <span class="bu">open</span>(curpus_path)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Step two consists in creating a corpus and switching to a TF-IDF representation. Here is where things change a bit. We need to define an iterable that yields documents in BoW representation, which is done by the <code>Corpus</code> class here below.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Corpus:</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Iterable that yields BoW representations of documents.'''</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, curpus_path, dct_object):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.curpus_path <span class="op">=</span> curpus_path</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dct_object <span class="op">=</span> dct_object</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> line <span class="kw">in</span> sopen(<span class="va">self</span>.curpus_path):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> <span class="va">self</span>.dct_object.doc2bow(tokenizer(line))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then use it to create our streamed corpus, which can be passed to <code>TfidfModel</code>. We’ll skip the explicit creation of the TF-IDF matrix because it can be very large.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> Corpus(curpus_path, dct)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>tfidf_model <span class="op">=</span> TfidfModel(corpus, id2word<span class="op">=</span>dct)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We are now ready to build our LSI model:</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>lsi_model <span class="op">=</span> LsiModel(corpus<span class="op">=</span>tfidf_model[corpus], id2word<span class="op">=</span>dct, num_topics<span class="op">=</span>dim_lsi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 3min 58s, sys: 11 s, total: 4min 9s
Wall time: 3min 17s</code></pre>
</div>
</div>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>We need to use iterables and not generators even though they both produce an iterator. This is because after we have exhausted a generator once there is no more data available. In contrast, iterables create a new iterator <em>every time</em> they are looped over. This is exactly what we need when creating a model: we need to be able to iterate over a dataset more than once.</p>
</div>
</div>
</section>
<section id="word2vec-model-1" class="level2">
<h2 class="anchored" data-anchor-id="word2vec-model-1">word2vec model</h2>
<p>Similar to what we did with the LSI model, we need to define an iterable that yields tokenized documents. This is provided by the <code>CorpusW2V</code> class below.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CorpusW2V:</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''Iterable that yields sentences (lists of str).'''</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, curpus_path):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.curpus_path <span class="op">=</span> curpus_path</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> line <span class="kw">in</span> sopen(<span class="va">self</span>.curpus_path):</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> tokenizer(line)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>corpus_w2v <span class="op">=</span> CorpusW2V(curpus_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The rest follows exactly as above, with the only difference that now the <code>.train()</code> method receives an instance of the <code>CorpusW2V</code> class instead of a list (see <code>tokenized_data</code> above).</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>w2v_model <span class="op">=</span> Word2Vec(</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span>dim_w2v, alpha<span class="op">=</span>alpha, min_alpha<span class="op">=</span>alpha_min, window<span class="op">=</span>wnd, </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    min_count<span class="op">=</span>mincount, sample<span class="op">=</span>sample, sg<span class="op">=</span>sg, negative<span class="op">=</span>ngt, workers<span class="op">=</span>threads</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Borrow LSI vocab.</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>word_freq <span class="op">=</span> {dct[k]: v <span class="cf">for</span> k,v <span class="kw">in</span> dct.cfs.items()}</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>w2v_model.build_vocab_from_freq(word_freq)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train model</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>num_samples <span class="op">=</span> dct.num_docs</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>w2v_model.train(corpus_w2v, total_examples<span class="op">=</span>num_samples, epochs<span class="op">=</span>epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 5min 52s, sys: 4.78 s, total: 5min 56s
Wall time: 6min 31s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>(2608743, 6277620)</code></pre>
</div>
</div>
<p>We conclude by noting that this approach based on data streaming is certainly <em>slower</em> than when we load everything into memory. However, it allows us to process arbitrarily large datasets. One can’t have it all, as they say.</p>
</section>
</section>
<section id="acknowledgements-and-references" class="level1">
<h1>Acknowledgements and references</h1>
<p>We must thank the Gensim community and in particular Austen Mack-Crane, on whose suggestions the section <a href="#LSI-and-word2vec-the-fast-way">LSI and word2vec the fast way</a> is based. The section <a href="#Data-streaming-%5Boptional%5D">Data streaming</a> takes instead inspiration from the <a href="https://radimrehurek.com/gensim/">Gensim documentation</a> and from Radim Řehůřek’s <a href="https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/">blog post</a> about data streaming in Python.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>